{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "#llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Initialize language model\n",
    "llm = ChatOpenAI(\n",
    "        api_key=\"ollama\",\n",
    "        model=\"llama3:latest\",\n",
    "        #model=\"gemma2:latest\", #respostas sempre em ingles\n",
    "        #model=\"splitpierre/bode-alpaca-pt-br:latest\", \n",
    "        #model=\"splitpierre/bode-alpaca-pt-br:13b-Q4_0\", \n",
    "        base_url=\"http://localhost:11434/v1\",\n",
    "        temperature=0, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, field_validator\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @field_validator('setup')\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != '?':\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field\n",
    "    \n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | parser\n",
    "\n",
    "res = chain.invoke(joke_query)\n",
    "\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the output in JSON format:\n",
      "\n",
      "```\n",
      "{\n",
      "    \"properties\": {\n",
      "        \"name\": {\"description\": \"name of an actor\", \"title\": \"Name\", \"type\": \"string\"},\n",
      "        \"film_names\": {\"description\": \"list of names of films they starred in\", \"items\": {\"type\": \"string\"}, \"title\": \"Film Names\", \"type\": \"array\"}\n",
      "    },\n",
      "    \"required\": [\"name\", \"film_names\"]\n",
      "}\n",
      "```\n",
      "\n",
      "Here is the output:\n",
      "\n",
      "```\n",
      "{\n",
      "    \"name\": \"Tom Hanks\",\n",
      "    \"film_names\": [\n",
      "        \"Forrest Gump\",\n",
      "        \"Cast Away\",\n",
      "        \"Saving Private Ryan\",\n",
      "        \"Apollo 13\",\n",
      "        \"The Green Mile\"\n",
      "    ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "\n",
    "# Here's another example, but with a compound typed field.\n",
    "class Actor(BaseModel):\n",
    "    name: str = Field(description=\"name of an actor\")\n",
    "    film_names: List[str] = Field(description=\"list of names of films they starred in\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Actor)\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "#chain = prompt_template | llm | parser\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "actor_query = \"Generate the filmography for a random actor.\"\n",
    "#actor_query = {'query':'Generate the filmography for Will Smith.'}\n",
    "#actor_query = {'query': 'Generate the filmography for Will Smith.'}\n",
    "\n",
    "# Run the LLMChain to get the AI-generated answer\n",
    "output = chain.run(actor_query)\n",
    "print( output )\n",
    "#parser.parse(output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suggestions(words=['conduct', 'manners', 'attitude', 'mannerisms', 'disruptiveness'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your desired data structure.\n",
    "class Suggestions(BaseModel):\n",
    "    words: List[str] = Field(description=\"list of substitue words based on context\")\n",
    "\n",
    "    # Throw error in case of recieving a numbered-list from API\n",
    "    @field_validator('words')\n",
    "    def not_start_with_number(cls, field):\n",
    "        if field[0].isnumeric():\n",
    "            raise ValueError(\"The word can not start with numbers!\")\n",
    "        return field\n",
    "    \n",
    "parser = PydanticOutputParser(pydantic_object=Suggestions)\n",
    "\n",
    "template = \"\"\"\n",
    "    Offer a list of suggestions to substitue the specified target_word based the presented context.\n",
    "    {format_instructions}\n",
    "    target_word={target_word}\n",
    "    context={context}\n",
    "\"\"\"\n",
    "\n",
    "target_word = \"behaviour\"\n",
    "context = \"The behaviour of the students in the classroom was disruptive and made it difficult for the teacher to conduct the lesson.\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template = template,\n",
    "    input_variables = [\"target_word\", \"context\"],\n",
    "    partial_variables = {\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "#chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "chain = prompt_template | llm | parser\n",
    "\n",
    "# Run the LLMChain to get the AI-generated answer\n",
    "#output = chain.run({\"target_word\": target_word, \"context\":context})\n",
    "output = chain.invoke({\"target_word\": target_word, \"context\":context})\n",
    "print( output )\n",
    "\n",
    "#parser.parse(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
